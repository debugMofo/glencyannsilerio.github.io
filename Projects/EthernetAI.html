<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link type="text/css" rel="stylesheet" href="../styles.css">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Bitcount+Prop+Single:wght@100..900&display=swap" rel="stylesheet">
        <title>Ethernet Straight-Through cable Image detection</title>
    </head>
    <body>
        <div>
           <h4 class="prismo">Ethernet Straight-Through-color coding labeler image detection</h4> 
        </div>
        <div>
            <span class="description">Description</span>
            <p class="description_paragraph">
              Used image Processing to determine the arrangement of Ethernet cable straight-through A color code.  
            </p>
        </div>
        <div class="container-1">
        <img class=prismo1 src="..\images\ethernet ai.png" alt="image-processing">
        <p>labels ethernet color strand from 1-8 in correct order base from straight thorugh B(T568B). <br>
            Using custom made dataset that is annotated using roboflow and trained using YOLOV8 image detection model.
        </p>
        </div>
        <div class="container-3">
            <img class=prismo2 src="..\images\results.png" alt="training result graph">
            <div class="anex-container-3-1">
                <p class="bullet">• training dashboard/plot produced by YOLOv8, a summary of how well the model learned during training.</p>
                <br>
                <br>
                <p class="bullet"><b>Training Loss</b></p>
                <br>
                <br>
                <p class="bullet">• train/box_loss, val/box_loss → Both steadily decrease from ~1.3 → ~0.5 (train) and ~1.1 → ~0.65 (val)
        ✅ This means the model is learning the bounding boxes well.</p>
                <br>
                <p class="bullet">• train/cls_loss, val/cls_loss → Start higher (~3 train, ~6 val) and drop to ~0.5–1
✅ Good convergence. Your strand classification is improving.</p>
                <br>
                <p class="bullet">• train/seg_loss, val/seg_loss → Smooth decline → segmentation (mask) is learning properly.</p>
                <br>
                <p class="bullet">• train/df1_loss, val/dfl_loss → Small decrease, stable → distribution focal loss is okay.</p>
                <br>
                <br>
                <p class="bullet"><b>Metrics</b></p>
                <br>
                <br>
                <p class="bullet">• Precision & Recall (B & M) → Both climb to ~0.9 for backbone and model output ✅ High precision → the model doesn’t mislabel much.✅ High recall → the model detects almost all strands.</p>
                <br>
                <p class="bullet">• mAP50 & mAP50-95 →

mAP50 (IoU 0.5) → ~0.9 (excellent)

mAP50-95 (IoU 0.5–0.95) → ~0.6 (decent, common for small objects)</p>
            </div>
        </div>
        <br>
        <div>
            <a href="https://drive.google.com/drive/folders/18wjze1DKMKVJGV81sXpcM63Q8eD7_HeI?usp=sharing">
                <button class="ethernet-btn">Link to project repository</button>
            </a>
        <div>
        <br>
    </body>

</html>